{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea44dfd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W =  [[0.27479841]] , W.shape =  (1, 1) , b =  [0.58518328] , b.shape =  (1,)\n",
      "Initial error value =  7.762118247624119 Initial W =  [[0.27479841]] \n",
      " , b =  [0.58518328]\n",
      "step =  0 error value =  4.57038972837331 W =  [[0.45923176]] , b =  [0.62592571]\n",
      "step =  400 error value =  0.0006840262163153737 W =  [[1.01698373]] , b =  [0.93869835]\n",
      "step =  800 error value =  4.3644916545314956e-05 W =  [[1.00429006]] , b =  [0.98451531]\n",
      "step =  1200 error value =  2.7848037031519408e-06 W =  [[1.00108366]] , b =  [0.99608859]\n",
      "step =  1600 error value =  1.7768693994490312e-07 W =  [[1.00027373]] , b =  [0.99901198]\n",
      "step =  2000 error value =  1.1337477248817378e-08 W =  [[1.00006914]] , b =  [0.99975043]\n",
      "step =  2400 error value =  7.233980753180315e-10 W =  [[1.00001747]] , b =  [0.99993696]\n",
      "step =  2800 error value =  4.6157073914614736e-11 W =  [[1.00000441]] , b =  [0.99998408]\n",
      "step =  3200 error value =  2.9450941959462127e-12 W =  [[1.00000111]] , b =  [0.99999598]\n",
      "step =  3600 error value =  1.8791442101245328e-13 W =  [[1.00000028]] , b =  [0.99999898]\n",
      "step =  4000 error value =  1.199005101660009e-14 W =  [[1.00000007]] , b =  [0.99999974]\n",
      "step =  4400 error value =  7.650361503232365e-16 W =  [[1.00000002]] , b =  [0.99999994]\n",
      "step =  4800 error value =  4.8813834117901965e-17 W =  [[1.]] , b =  [0.99999998]\n",
      "step =  5200 error value =  3.114611881157713e-18 W =  [[1.]] , b =  [1.]\n",
      "step =  5600 error value =  1.9873066603364035e-19 W =  [[1.]] , b =  [1.]\n",
      "step =  6000 error value =  1.268022975523066e-20 W =  [[1.]] , b =  [1.]\n",
      "step =  6400 error value =  8.090762477573434e-22 W =  [[1.]] , b =  [1.]\n",
      "step =  6800 error value =  5.1620817627679595e-23 W =  [[1.]] , b =  [1.]\n",
      "step =  7200 error value =  3.2962979698409704e-24 W =  [[1.]] , b =  [1.]\n",
      "step =  7600 error value =  2.1113203429384523e-25 W =  [[1.]] , b =  [1.]\n",
      "step =  8000 error value =  1.3571918000829637e-26 W =  [[1.]] , b =  [1.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[44.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_data = np.array([1,2,3,4,5]).reshape(5,1)\n",
    "t_data = np.array([2,3,4,5,6]).reshape(5,1)\n",
    "\n",
    "W = np.random.rand(1,1)\n",
    "b = np.random.rand(1)\n",
    "print(\"W = \", W, \", W.shape = \", W.shape, \", b = \", b, \", b.shape = \", b.shape)\n",
    "\n",
    "def loss_func(x, t):\n",
    "    y = np.dot(x, W)+b\n",
    "    return ( np.sum((t-y)**2) ) / ( len(x) )\n",
    "\n",
    "def numerical_derivative(f, x):\n",
    "    delta_x = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x)\n",
    "        \n",
    "        x[idx] = tmp_val - delta_x\n",
    "        fx2 = f(x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val\n",
    "        it.iternext()\n",
    "        \n",
    "    return grad\n",
    "\n",
    "def predict(x):\n",
    "    y = np.dot(x,W) + b\n",
    "    \n",
    "    return y\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "f = lambda x : loss_func(x_data, t_data)\n",
    "\n",
    "print(\"Initial error value = \", loss_func(x_data, t_data), \"Initial W = \", W, \"\\n\", \", b = \", b)\n",
    "\n",
    "for step in range(8001):\n",
    "    \n",
    "    W -= learning_rate * numerical_derivative(f, W)\n",
    "    b -= learning_rate * numerical_derivative(f, b)\n",
    "    \n",
    "    if (step % 400 == 0):\n",
    "        print(\"step = \", step, \"error value = \", loss_func(x_data, t_data), \"W = \", W, \", b = \", b)\n",
    "        \n",
    "predict(43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb22b05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
